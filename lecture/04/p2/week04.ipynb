{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib ipympl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Week 04, ASTR 496: Foundations of Data Science in Astrophysics\n",
    "\n",
    "\n",
    "## A Gentle introduction to Optimization\n",
    "\n",
    "### Gautham Narayan \n",
    "##### <gsn@illinois.edu>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "\n",
    "## Recap: Statistical Modeling \"Wisdom\"\n",
    "\n",
    "Four Questions for a Bayesian:\n",
    "\n",
    "1. What is the model?\n",
    "\n",
    "2. What is the likelihood? Derive $L(\\theta)$ from your sampling distribution $P(D|\\theta)$\n",
    "\n",
    "3. What are your priors $P(\\theta)$?\n",
    "\n",
    "4. How do you optimize/sample this objective function to model the data?\n",
    "\n",
    "We've talked a lot about Q1 and Q2, less about Q3, and for Q4 we've been working through different methods: grid-search, gradient descent (i.e. scipy's fmin/optimize) \n",
    "\n",
    "We'll return to Q3, but to make progress, we need to deal with Q4 first because we're limiting the sorts of problems we can deal with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "So far, we've restricted ourselves to inferences with:\n",
    "* exact solutions - rare!\n",
    "* linear-izable functions - because these are convex, and minimum is the global minimum!\n",
    "* low-dimensional parameter spaces - limiting!\n",
    "\n",
    "We can think of more complicated scenarios:\n",
    "\n",
    "![Posteriors](./posteriors.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![CMD](cmd_all.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Planet Posterior](Planet_posterior.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Newton's Method (sometimes Newton-Raphson)\n",
    "\n",
    "Goal: Want to find $x_c$, such that $f(x = x_c) = 0$ \n",
    "\n",
    "1. Make an initial guess that is half-way reasonable \n",
    "\n",
    "2. Iterate $ x_{n+1} = x_n - f(x_n)/f^\\prime(x_n) $\n",
    "\n",
    "\n",
    "![Newton-Raphson](NewtonRaphson.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Many function minimization algorithms are based on the fundamental idea of **gradient descent.** \n",
    "\n",
    "If a function f is differentiable, then at every point, the opposite of its gradient points to the direction of the greatest decrease rate of the function. \n",
    "\n",
    "By following this direction, we can expect to find a local minimum.\n",
    "\n",
    "\n",
    "![Newton-Raphson](NewtonRaphson.png)\n",
    "\n",
    "\n",
    "If you can compute an analytical expression of the gradient, you should provide it to the minimization routine. Otherwise, the algorithm will compute an approximation of the gradient that may not be reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Newton's method can also be used in this context of function minimization. \n",
    "\n",
    "The idea is to find a root of the (derivative of the Likelihood with Newton's method (i.e. $f = L^{\\prime}$), thereby making use of the second derivative . \n",
    "\n",
    "In other words, we approximate the likelihood $L$ with a quadratic function instead of a linear function. \n",
    "\n",
    "In multiple dimensions, this is done by computing the Hessian (second derivatives) of $L$. \n",
    "\n",
    "By performing this operation iteratively, we can expect the algorithm to converge towards a local minimum.\n",
    "\n",
    "This is what scipy.optimize is doing by default (actually now they've switched to BFGS) which is a Quasi-Newton method but not all that different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class exercise:\n",
    "\n",
    "Let's create a complicated e.g. of a likelihood in 2 dimensions.\n",
    "You get to use scipy's optimize Nelder-Mead to figure out the minimum of this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# RUN THIS\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy import optimize\n",
    "\n",
    "\n",
    "def eggholder(x):\n",
    "    return (-(x[1] + 47) * np.sin(np.sqrt(abs(x[0]/2 + (x[1]  + 47))))\\\n",
    "            -x[0] * np.sin(np.sqrt(abs(x[0] - (x[1]  + 47)))))\n",
    "\n",
    "bounds = [(-512, 512), (-512, 512)]\n",
    "\n",
    "x = np.arange(-512, 513)\n",
    "y = np.arange(-512, 513)\n",
    "xgrid, ygrid = np.meshgrid(x, y)\n",
    "xy = np.stack([xgrid, ygrid])\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(45, -45)\n",
    "ax.plot_surface(xgrid, ygrid, eggholder(xy), cmap='terrain')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('eggholder(x, y)');\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# use optimize.minimize to try to find the minimum\n",
    "# try it 10 times with different starting guesses\n",
    "# print out the minimum value, and the x, y location of the minimum\n",
    "# since you already have the true function, get the minimum value \n",
    "# and the location of the minimum of your x, y grid\n",
    "\n",
    "    \n",
    "# you should notice how the minimum value is all over the place based on your starting guess."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Global Optimizers (use if you have a complex problem but low dimensionality)\n",
    "\n",
    "\n",
    "Generally, these use a two step approach - something to take large steps to avoid local minima + another step to find the minima near the best of the big steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simulated annealing\n",
    "\n",
    "Mimics the physical process of heating a material and then slowly lowering the temperature to decrease defects, thus minimizing the system energy.\n",
    "\n",
    "At each iteration of the simulated annealing algorithm, a new point is randomly generated. \n",
    "\n",
    "The distance of the new point from the current point, or the extent of the search, is based on a probability distribution \n",
    "\n",
    "## $$ P = \\exp(-\\Delta L/kT) $$\n",
    "\n",
    "\n",
    "\n",
    "The algorithm accepts all new points that lower the objective, but also, with a certain probability, points that raise the objective. \n",
    "\n",
    "By accepting points that raise the objective, the algorithm avoids being trapped in local minima, and is able to explore globally for more possible solutions.\n",
    "\n",
    "![Simulated Annealing](sim_annealing_flow.png)\n",
    "\n",
    "\n",
    "An annealing schedule is selected to systematically decrease the temperature as the algorithm proceeds. \n",
    "\n",
    "As the temperature decreases, the algorithm reduces the extent of its search to converge to a minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Basin-hopping algorithm is a stochastic algorithm that seeks a global minimum by combining random perturbation of the positions and local minimization.\n",
    "\n",
    "`scipy.optimize.basinhopping`\n",
    "\n",
    "![Basin Hopping](basin_hopping.png)\n",
    "\n",
    "(from Hashimi & Shehu, 2013 - [\"HopDock: a probabilistic search algorithm for decoy sampling in protein-protein docking\"](https://proteomesci.biomedcentral.com/articles/10.1186/1477-5956-11-S1-S6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Simplicial homology global optimization (SHGO) is another good option, particularly since it also returns all other local and global minimum in addition to the global minimum. \n",
    "\n",
    "It's using \"novel, rigorously proven\" methods that detect the homological properties of the objective function surface). \n",
    "\n",
    "![SHGO](shgo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use Basin-hopping, simulated annealing and SHGO to solve the eggholder problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class MyBounds(object):\n",
    "    def __init__(self, xmax=[512, 512], xmin=[-512,-512] ):\n",
    "        self.xmax = np.array(xmax)\n",
    "        self.xmin = np.array(xmin)\n",
    "    def __call__(self, **kwargs):\n",
    "        x = kwargs[\"x_new\"]\n",
    "        tmax = bool(np.all(x <= self.xmax))\n",
    "        tmin = bool(np.all(x >= self.xmin))\n",
    "        return tmax and tmin\n",
    "\n",
    "bounds = MyBounds()\n",
    "res1 = optimize.basinhopping(eggholder, st.uniform.rvs(loc=-512, scale=1024, size=2),\\\n",
    "                             niter=10000, T=1, accept_test=bounds, seed=42)\n",
    "print('Basin Hopping')\n",
    "print(res1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print('-------------')\n",
    "res2 = optimize.shgo(eggholder, bounds=[(-512, 512), (-512, 512)], n=30, sampling_method='sobol')\n",
    "print('SHGO')\n",
    "print(res2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Curse of Dimensionality\n",
    "\n",
    "![Curse of Dimensionality](ndim.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You'll do something very different on your 2nd homework assignment\n",
    "\n",
    "- you'll simulate the experiment over and over, drawing random samples from a distribution of your parameter\n",
    "\n",
    "- you'll pick those draws where the simulated experiment matched your real data (Alice has won 5 games by game 8, Bob wins at the end) \n",
    "    - i.e. you rejected the others\n",
    "\n",
    "- you determined the frequency of the outcome you are interested in happening."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A history of the Monte Carlo method and the Manhattan project:\n",
    "https://permalink.lanl.gov/object/tr?what=info:lanl-repo/lareport/LA-UR-88-9068\n",
    "\n",
    "\n",
    "In general, evaluating the posterior throughout the entire parameter space is too costly. \n",
    "\n",
    "We want to focus resources on mapping the posterior where it is non-tiny. \n",
    "\n",
    "**Generating samples from the posterior itself automatically accomplishes this.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sampling and numerical integration\n",
    "\n",
    "Almost always, we are ultimately interested in *integrals* of the posterior, i.e. marginal distributions of parameters. The tasks of Monte Carlo sampling and **Monte Carlo integration** are essentially indistinguishable. (Similar machinery is useful for difficult optimization problems.)\n",
    "\n",
    "The essence of MC integration:\n",
    "\n",
    "$\\int w(x)\\,p(x)\\,dx = \\int w(x)\\,dP(x) \\approx \\overline{w(x_i)}; ~ x_i\\sim P$\n",
    "\n",
    "i.e., if we can factor the integrand into a PDF and a weight, and sample from the PDF, then our integral becomes an _average over the samples_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "In other words, given a list of samples of $\\theta$ from $p(\\theta)$,\n",
    "* the marginalized 1D posterior for $\\theta_0$ is estimated by making a histogram of $\\theta_0$ samples\n",
    "* the marginalized 2D posterior for $\\theta_0,\\theta_1$ is estimated from a 2D histogram of $\\theta_0,\\theta_1$ samples\n",
    "* statistics like the mean or percentiles of the posterior are estimated directly from the samples\n",
    "\n",
    "All of these computations would be weighted if $w(\\theta)\\neq1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Simple Example\n",
    "\n",
    "Area of a rectangle = Base $\\times$ Height\n",
    "Area of a triangle = 1/2 Base $\\times$ Height\n",
    "What about the area of this?\n",
    "\n",
    "![Messy Area](messy_area.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Conditional probability](conditional_prob.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Conditional probability](conditional_prob2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Simple Monte Carlo\n",
    "\n",
    "A posterior is already naturally factored into a likelihood function and a prior PDF.\n",
    "\n",
    "$p(\\theta|x) \\propto p(x|\\theta)\\,p(\\theta)$\n",
    "\n",
    "Applying this in the MC integration context leads to the Simple Monte Carlo algorithm:\n",
    "\n",
    "```\n",
    "while we want more samples\n",
    "    draw theta from p(theta)\n",
    "    compute weight = p(x|theta)\n",
    "    store theta and weight\n",
    "```\n",
    "\n",
    "Obtaining marginal distribution(s) for $\\theta$ then reduces to constructing weighted histograms of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "SMC is indeed simple (as long as the prior is simple to draw from), but if the priors are not very informative then it still wastes many likelihood evaluations where the posterior is small. However, refinements of this approach lead to some of the advanced algorithms we'll cover later.\n",
    "\n",
    "For now, we'll focus on the most common methods, which use a unit weight function (i.e. obtain draws directly from the posterior).\n",
    "\n",
    "But first, a bit more context re: random number generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random number generation\n",
    "Useful terms to know:\n",
    "\n",
    "* Random: predictable only in the sense of following a PDF\n",
    "\n",
    "* Pseudorandom: not random, but \"unpredictable enough\" for practical purposes. Various computer algorithms produce pseudorandom sequences that approximate the uniform distribution on [0,1).\n",
    "\n",
    "* Quasirandom: sequence that doesn't even pretend to be random, but does converge to a target PDF *more quickly* than a random or pseudorandom process would"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Here we assume that we have a reliable source of uniform pseudorandom numbers, and want to turn these into samples of another PDF.\n",
    "\n",
    "Two simple approaches are\n",
    "1. Rejection sampling\n",
    "2. Inverse Transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# In class exercise - rejection sampling\n",
    "\n",
    "You'll use rejection sampling in HW2\n",
    "\n",
    "- Draw x, y points from a uniform distribution between 0 and 1\n",
    "- Sample size = [10, 1,000, 100,000]\n",
    "- calculate r = sqrt(x^2 + y^2)\n",
    "- reject if r > 1, else accept\n",
    "- plot the accepted points in red and the rejected points in blue in the x-y plane\n",
    "- calculate pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "### YOUR ANSWER HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![Conditional probability](conditional_prob3.png)\n",
    "Courtesy: Federica Bianco"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* Simple MC with uniform sampling of parameter space **does not solve curse of dimensionality (too many useless samples in low likelihood region)** \n",
    "* What if, instead of sampling the parameter space uniformly, you could sample the posterior directly\n",
    "    * Possible outcomes would be **simulated with a frequency proportional to the probability**\n",
    "    \n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Likelihood_Surface.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are a couple of approaches to this:\n",
    " \n",
    "### 1. Rejection sampling\n",
    "For this method, we need to define an *envelope function* which everywhere exceeds the target PDF, $p(x)$, and can be sampled. Let this be $Ag(x)$ where $A$ is a scaling factor and $g(x)$ is a PDF we know.\n",
    "\n",
    "Then the algorithm is\n",
    "```\n",
    "while we want more samples\n",
    "    draw a random value for x from some distribution g in the variable x\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= p(x)/(A*g(x)), keep the sample x\n",
    "    otherwise, reject x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Visually, this corresponds to drawing points that uniformly fill in the space under $p(x)$.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"mc1_rejection.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "Courtesy: Phil Marshall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The second approach you've already seen and used a lot:\n",
    "\n",
    "### 2. The Inverse Transform \n",
    "\n",
    "The definition of the CDF (and it's inverse, $F^{-1}$, the quantile function - i.e. `ppf()` in `scipy.stats`) \n",
    "\n",
    "$F(x) = P(X \\leq x) = \\int_{-\\infty}^x p(x')\\,dx'$\n",
    "\n",
    "By this definition, quantiles of $X$ are uniformly distributed on [0,1]. If $F^{-1}$ is easy to evaluate, we can use this straightforwardly:\n",
    "\n",
    "```\n",
    "draw u from Uniform(0,1)\n",
    "compute x = F_inverse(u)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "* This does solve the problem posed by the curse of dimensionality \n",
    "\n",
    "* No sample is rejected! \n",
    "\n",
    "* The con is that you have to know what p(x) looks like in advance\n",
    "\n",
    "* If p(x) is your posterior, then you not only need to be able to solve for it analytically (including the evidence - the denominator of Bayes' theorem) but then you've got to figure out how to invert it... even harder.\n",
    "    \n",
    "* There is a place for the PIT, but we started down this road because our functions weren't generally going to be nice, so lets deal with rejection sampling some more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# We want a couple of properties\n",
    "\n",
    "* We want to sample the full distribution \n",
    "* We want the frequency of samples between $x$ and $x+dx$ to be proportional to $p(x)dx$\n",
    "\n",
    "What if, instead of drawing i.i.d samples, we drew samples such that they are correlated with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "You have already seen examples of processes where samples are correlated with each other - Brownian motion/random walks/Wiener processes - all of these are examples of **stochastic** processes\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"Wiener_process_3d.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " What if we chose our samples to be correlated in a very specific way:\n",
    "   * decide how many samples you want\n",
    "   * start somewhere - we'll call our current position in k-dimensional parameter space $x$\n",
    "   * while you want samples:\n",
    "       * perturb $x$ to $x'$ by some random vector drawn from a fixed distribution   \n",
    "           * i.e. the samples are correlated\n",
    "       * evaluate your function at $x'$ and $x$\n",
    "       * if the function is higher at $x'$ than at $x$ \n",
    "           * then yay! Accept it, and set the position $x'$ to the current position $x$\n",
    "       * else if the function is lower at $x'$ than at $x$\n",
    "           * well maybe that's bad, or maybe we're just unlucky and there's good samples to be had near here\n",
    "           * How do we decide? Well let's draw a random number and check if our function ratio is better or worse\n",
    "               * if it's better, accept and set the position $x'$ to the current position $x$\n",
    "               * else reject and update the current position to be the same \n",
    "       * stick the current position after you did this into a list of samples \n",
    "    \n",
    "This sequence/list of all accepted samples is a **chain**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This is just our **rejection sampling** strategy (recall):\n",
    "\n",
    "```\n",
    "while we want more samples\n",
    "    draw a random value for x from some distribution g in the variable x\n",
    "    draw u from Uniform(0,1)\n",
    "    if u <= p(x)/(A*g(x)), keep the sample x\n",
    "    otherwise, reject x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Markov Chains:\n",
    "\n",
    "If we can construct a sequence of samples/chain this way, it will be **ergodic** - i.e. given enough time, the full distribution will be sampled\n",
    "\n",
    "This chain is from some n-dimensional parameter space, with a distribution that is asymptotically proportional to $p(x)$. \n",
    "\n",
    "**(NOTE THAT I SHOULD REALLY BE WRITING $\\theta$ NOT $x$ BUT YOU TRYING DOING THIS OVER AND OVER!)**\n",
    "\n",
    "The constant of proportionality is not important in the first class of problems we will look at. \n",
    "\n",
    "In model comparison problems, the proportionality constant must be known. We've glossed over that so far, so we will blithely push forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "With our particular strategy, every n+1 th position on the chain depends **only** on the nth position:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"MarkovChain.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Chains that have this property are called **Markov Chains**.\n",
    "\n",
    "The **state space** of this stochastic process is the set of all possible values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Go here:\n",
    "[http://setosa.io/ev/markov-chains/](http://setosa.io/ev/markov-chains/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* If you have a finite state space, then you write down transition probabilities from one state to another as a matrix or represent it with a graph\n",
    "\n",
    "* Usually in science, our parameters do not have discrete states, but take values from the set of real numbers,  ${\\rm I\\!R}$ - i.e. there are an (uncountably) infinite number of states, and we don't have single dimensional problems\n",
    "\n",
    "    * Can't represent this as a matrix/graph anymore\n",
    "    \n",
    "* Essential elements of this theory still hold in an infinite dimensional state space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "As long as the Markov chain is **positive recurrent** (i.e. you can get to any parameter in a finite number of steps) and is **irreducible** (you can get to every parameter value from every other parameter value) then it has another nice property  - it is **stationary** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "A subset of Markov Chains are **stationary**\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"StationaryMarkovChain.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "The average of some function over the samples in the Markov chain is asymptotically equal to the expectation value of the function over the underlying stationary distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"ReversibleMarkovChain.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "### **All reversible chains are stationary, but not vice-versa!** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The particular algorithm for generating new samples (more properly detailed in HW2, which is coming up) is called **Metropolis-Hastings** after the folks that came up with it.\n",
    "\n",
    "In summary, the Metropolis-Hastings algorithm consists of these steps:\n",
    "\n",
    "1. given $x$ and $T(x'|x)$, draw a proposed value for $x'$\n",
    "\n",
    "2. compute acceptance probability $p_{\\rm acc}(x,x')$.\n",
    "\n",
    "3. draw a random number between 0 and 1 from a uniform distribution; if it smaller than $p_{\\rm acc}(x,x')$, then accept $x'$.\n",
    "\n",
    "4. if $x'$ is accepted added it to the chain, if not, add $x'$ to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('<iframe width=\"560\" height=\"315\" src=\"https://www.youtube.com/embed/Vv3f0QNWvWQ?rel=0&amp;controls=0&amp;showinfo=0\" frameborder=\"0\" allowfullscreen></iframe>')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This process is NOT **stationary**. \n",
    "\n",
    "#### Why does it work?\n",
    "The probability of an arbitrary point from such a chain being located at $x'$ is (marginalizing over the possible immediately preceding points)\n",
    "\n",
    "## $$p(x') = \\int dx \\, p(x) \\, T(x'|x)$$\n",
    "\n",
    "where $T(x'|x)$ is the transition probability of a step from $x$ to $x'$.\n",
    "\n",
    "If we have detailed balance, \n",
    "\n",
    "## $$p(x)T(x'|x) = p(x')T(x|x')$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "rearranging:\n",
    "\n",
    "## $$ \\frac{T(x'|x)}{T(x|x')} = \\frac{p(x')}{p(x)} $$\n",
    "\n",
    "The basic trick to connect this with rejection sampling is to break the transition into two steps:\n",
    "1. A proposal, g(x'| x)\n",
    "and \n",
    "2. Acceptance ratio, A(x'|x)\n",
    "\n",
    "i.e. \n",
    "\n",
    "## $$ T(x'|x) = A(x'|x) g(x'| x) $$ \n",
    "\n",
    "rearranging again :\n",
    "\n",
    "## $$ \\frac{A(x'|x)}{A(x|x')} = \\frac{p(x')g(x|x')}{p(x)g(x'|x) }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Notice that the probability of accepting a step  (once it's proposed) is\n",
    "\n",
    "## $$A(x',x) = \\mathrm{min}\\left[1, \\frac{p(x')g(x|x')}{p(x)g(x'|x)}\\right]$$\n",
    "\n",
    "Let's look again at the requirement of detailed balance\n",
    "\n",
    "> the probability of being at $x$ and moving to $y$ must equal the probability of being at $x'$ and moving to $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first of these is $p(x)g(x'|x)A(x',x)$, where\n",
    "\n",
    "* $p(x)$ is the posterior density (probability of *being* at $x$, if we're sampling $P$ properly)\n",
    "\n",
    "* $g(x'|x)$ is the proposal distribution (probability of attempting a move to $x'$ from $x$)\n",
    "\n",
    "* $A(x',x)$ is the probability of accepting the proposed move\n",
    "\n",
    "With this definition of $A$, detailed balance is automatically satisfied!\n",
    "\n",
    "## $$p(x)g(x'|x)A(x',x) \\equiv p(x')g(x|x')A(x,x')$$\n",
    "\n",
    "Note that **even if a step is rejected, we still keep a sample** (the original state, without moving). The difficulty of finding a temptingly better point is important information!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "How far should we step (small steps in parameter space or large). This impacts the efficiency of the process but not if we will reach equilibrium.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td><img src=\"sampling.png\" width=100%></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>\"Well that's easy, MCMC generates samples from the posterior distribution by constructing an ergodic, reversible Markov-chain that has as its equilibrium distribution the target posterior distribution. Questions?\" </center>\n",
    "### <center> - Thomas Wiecki, very tongue in cheek </center>\n",
    "\n",
    "https://twiecki.io/blog/2015/11/10/mcmc-sampling/"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:astr496] *",
   "language": "python",
   "name": "conda-env-astr496-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
